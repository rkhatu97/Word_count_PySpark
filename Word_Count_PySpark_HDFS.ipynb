{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark import SparkConf, SQLContext\n",
    "sparkSession = SparkSession.builder.appName(\"word-count\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|sentence                                                                                                                                                                                                                                                                                |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|apache spark                                                                                                                                                                                                                                                                            |\n",
      "|                                                                                                                                                                                                                                                                                        |\n",
      "|spark is a unified analytics engine for large scale data processing  it provides                                                                                                                                                                                                        |\n",
      "|high level apis in scala  java  python  and r  and an optimized engine that                                                                                                                                                                                                             |\n",
      "|supports general computation graphs for data analysis  it also supports a                                                                                                                                                                                                               |\n",
      "|rich set of higher level tools including spark sql for sql and dataframes                                                                                                                                                                                                               |\n",
      "|mllib for machine learning  graphx for graph processing                                                                                                                                                                                                                                 |\n",
      "|and structured streaming for stream processing                                                                                                                                                                                                                                          |\n",
      "|                                                                                                                                                                                                                                                                                        |\n",
      "|https spark apache org                                                                                                                                                                                                                                                                  |\n",
      "|                                                                                                                                                                                                                                                                                        |\n",
      "|jenkins build https amplab cs berkeley edu jenkins job spark master test sbt hadoop 2 7 hive 2 3 badge icon https amplab cs berkeley edu jenkins job spark master test sbt hadoop 2 7 hive 2 3                                                                                          |\n",
      "|appveyor build https img shields io appveyor ci apachesoftwarefoundation spark master svg style plastic logo appveyor https ci appveyor com project apachesoftwarefoundation spark                                                                                                      |\n",
      "|pyspark coverage https img shields io badge dynamic xml svg label pyspark 20coverage url https 3a 2f 2fspark test github io 2fpyspark coverage site query 2fhtml 2fbody 2fdiv 5b1 5d 2fdiv 2fh1 2fspan colorb brightgreen style plastic https spark test github io pyspark coverage site|\n",
      "|                                                                                                                                                                                                                                                                                        |\n",
      "|                                                                                                                                                                                                                                                                                        |\n",
      "|online documentation                                                                                                                                                                                                                                                                    |\n",
      "|                                                                                                                                                                                                                                                                                        |\n",
      "|you can find the latest spark documentation  including a programming                                                                                                                                                                                                                    |\n",
      "|guide  on the  project web page https spark apache org documentation html                                                                                                                                                                                                               |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim, col, lower\n",
    "def removePunctuation(column):\n",
    "    return trim(lower(regexp_replace(column, '([^\\s\\w_]|_)+', ' '))).alias('sentence')\n",
    "words = sparkSession.read.text('hdfs://localhost:9820/test/README.md').select(removePunctuation(col('value')))\n",
    "words.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|    apache|\n",
      "|     spark|\n",
      "|     spark|\n",
      "|        is|\n",
      "|         a|\n",
      "|   unified|\n",
      "| analytics|\n",
      "|    engine|\n",
      "|       for|\n",
      "|     large|\n",
      "|     scale|\n",
      "|      data|\n",
      "|processing|\n",
      "|        it|\n",
      "|  provides|\n",
      "|      high|\n",
      "|     level|\n",
      "|      apis|\n",
      "|        in|\n",
      "|     scala|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "689\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "WordsSplitDF = (words.select(split(words.sentence, '\\s+').alias('split')))\n",
    "WordsSingleDF = (WordsSplitDF.select(explode(WordsSplitDF.split).alias('word')))\n",
    "WordsDF = WordsSingleDF.where(WordsSingleDF.word != '')\n",
    "WordsDF.show()\n",
    "WordsDFCount = WordsDF.count()\n",
    "print(WordsDFCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|word                    |count|\n",
      "+------------------------+-----+\n",
      "|spark                   |38   |\n",
      "|the                     |25   |\n",
      "|to                      |18   |\n",
      "|https                   |16   |\n",
      "|for                     |15   |\n",
      "|run                     |13   |\n",
      "|and                     |11   |\n",
      "|apache                  |11   |\n",
      "|a                       |10   |\n",
      "|org                     |9    |\n",
      "|hadoop                  |9    |\n",
      "|building                |8    |\n",
      "|example                 |8    |\n",
      "|you                     |8    |\n",
      "|html                    |7    |\n",
      "|tests                   |7    |\n",
      "|on                      |7    |\n",
      "|is                      |7    |\n",
      "|documentation           |6    |\n",
      "|build                   |6    |\n",
      "|can                     |6    |\n",
      "|1000                    |6    |\n",
      "|000                     |6    |\n",
      "|in                      |5    |\n",
      "|shell                   |5    |\n",
      "|of                      |5    |\n",
      "|master                  |5    |\n",
      "|bin                     |5    |\n",
      "|test                    |5    |\n",
      "|also                    |5    |\n",
      "|please                  |4    |\n",
      "|latest                  |4    |\n",
      "|pyspark                 |4    |\n",
      "|an                      |4    |\n",
      "|project                 |4    |\n",
      "|programs                |4    |\n",
      "|including               |4    |\n",
      "|io                      |4    |\n",
      "|yarn                    |4    |\n",
      "|appveyor                |4    |\n",
      "|scala                   |4    |\n",
      "|tools                   |4    |\n",
      "|if                      |4    |\n",
      "|examples                |4    |\n",
      "|2                       |4    |\n",
      "|python                  |4    |\n",
      "|using                   |4    |\n",
      "|hive                    |4    |\n",
      "|coverage                |3    |\n",
      "|guide                   |3    |\n",
      "|use                     |3    |\n",
      "|built                   |3    |\n",
      "|contributing            |3    |\n",
      "|with                    |3    |\n",
      "|see                     |3    |\n",
      "|class                   |3    |\n",
      "|locally                 |3    |\n",
      "|developer               |3    |\n",
      "|package                 |3    |\n",
      "|docs                    |3    |\n",
      "|how                     |3    |\n",
      "|jenkins                 |3    |\n",
      "|this                    |3    |\n",
      "|processing              |3    |\n",
      "|or                      |3    |\n",
      "|version                 |3    |\n",
      "|configuration           |3    |\n",
      "|site                    |3    |\n",
      "|local                   |2    |\n",
      "|enabling                |2    |\n",
      "|svg                     |2    |\n",
      "|set                     |2    |\n",
      "|do                      |2    |\n",
      "|job                     |2    |\n",
      "|level                   |2    |\n",
      "|general                 |2    |\n",
      "|running                 |2    |\n",
      "|should                  |2    |\n",
      "|one                     |2    |\n",
      "|sql                     |2    |\n",
      "|online                  |2    |\n",
      "|following               |2    |\n",
      "|plastic                 |2    |\n",
      "|supports                |2    |\n",
      "|range                   |2    |\n",
      "|github                  |2    |\n",
      "|count                   |2    |\n",
      "|specifying              |2    |\n",
      "|return                  |2    |\n",
      "|n                       |2    |\n",
      "|cluster                 |2    |\n",
      "|be                      |2    |\n",
      "|integration             |2    |\n",
      "|interactive             |2    |\n",
      "|params                  |2    |\n",
      "|guidance                |2    |\n",
      "|cs                      |2    |\n",
      "|url                     |2    |\n",
      "|shields                 |2    |\n",
      "|command                 |2    |\n",
      "|3                       |2    |\n",
      "|sbt                     |2    |\n",
      "|berkeley                |2    |\n",
      "|amplab                  |2    |\n",
      "|1                       |2    |\n",
      "|apachesoftwarefoundation|2    |\n",
      "|style                   |2    |\n",
      "|versions                |2    |\n",
      "|at                      |2    |\n",
      "|ci                      |2    |\n",
      "|7                       |2    |\n",
      "|that                    |2    |\n",
      "|edu                     |2    |\n",
      "|2fdiv                   |2    |\n",
      "|sparkpi                 |2    |\n",
      "|kubernetes              |2    |\n",
      "|maven                   |2    |\n",
      "|detailed                |2    |\n",
      "|readme                  |2    |\n",
      "|particular              |2    |\n",
      "|data                    |2    |\n",
      "|it                      |2    |\n",
      "|engine                  |2    |\n",
      "|img                     |2    |\n",
      "|individual              |2    |\n",
      "|refer                   |2    |\n",
      "|badge                   |2    |\n",
      "|which                   |2    |\n",
      "|distributions           |1    |\n",
      "|abbreviated             |1    |\n",
      "|graphs                  |1    |\n",
      "|scale                   |1    |\n",
      "|pi                      |1    |\n",
      "|name                    |1    |\n",
      "|rich                    |1    |\n",
      "|instance                |1    |\n",
      "|2fspark                 |1    |\n",
      "|thread                  |1    |\n",
      "|not                     |1    |\n",
      "|instructions            |1    |\n",
      "|provides                |1    |\n",
      "|com                     |1    |\n",
      "|overview                |1    |\n",
      "|must                    |1    |\n",
      "|icon                    |1    |\n",
      "|logo                    |1    |\n",
      "|2fh1                    |1    |\n",
      "|page                    |1    |\n",
      "|stream                  |1    |\n",
      "|configure               |1    |\n",
      "|graphx                  |1    |\n",
      "|more                    |1    |\n",
      "|will                    |1    |\n",
      "|learning                |1    |\n",
      "|when                    |1    |\n",
      "|mvn                     |1    |\n",
      "|information             |1    |\n",
      "|because                 |1    |\n",
      "|dskiptests              |1    |\n",
      "|dev                     |1    |\n",
      "|library                 |1    |\n",
      "|contains                |1    |\n",
      "|5b1                     |1    |\n",
      "|protocols               |1    |\n",
      "|core                    |1    |\n",
      "|structured              |1    |\n",
      "|basic                   |1    |\n",
      "|variable                |1    |\n",
      "|there                   |1    |\n",
      "|talk                    |1    |\n",
      "|streaming               |1    |\n",
      "|your                    |1    |\n",
      "|managers                |1    |\n",
      "|resource                |1    |\n",
      "|graph                   |1    |\n",
      "|alternatively           |1    |\n",
      "|contribution            |1    |\n",
      "|sample                  |1    |\n",
      "|way                     |1    |\n",
      "|useful                  |1    |\n",
      "|mesos                   |1    |\n",
      "|hdfs                    |1    |\n",
      "|submit                  |1    |\n",
      "|other                   |1    |\n",
      "|info                    |1    |\n",
      "|environment             |1    |\n",
      "|print                   |1    |\n",
      "|apis                    |1    |\n",
      "|query                   |1    |\n",
      "|ide                     |1    |\n",
      "|colorb                  |1    |\n",
      "|started                 |1    |\n",
      "|storage                 |1    |\n",
      "|label                   |1    |\n",
      "|module                  |1    |\n",
      "|developing              |1    |\n",
      "|host                    |1    |\n",
      "|programming             |1    |\n",
      "|downloaded              |1    |\n",
      "|comes                   |1    |\n",
      "|machine                 |1    |\n",
      "|given                   |1    |\n",
      "|5d                      |1    |\n",
      "|file                    |1    |\n",
      "|same                    |1    |\n",
      "|mllib                   |1    |\n",
      "|2fhtml                  |1    |\n",
      "|2f                      |1    |\n",
      "|higher                  |1    |\n",
      "|high                    |1    |\n",
      "|are                     |1    |\n",
      "|requires                |1    |\n",
      "|optimized               |1    |\n",
      "|setup                   |1    |\n",
      "|7077                    |1    |\n",
      "|clean                   |1    |\n",
      "|them                    |1    |\n",
      "|easiest                 |1    |\n",
      "|systems                 |1    |\n",
      "|review                  |1    |\n",
      "|several                 |1    |\n",
      "|once                    |1    |\n",
      "|20coverage              |1    |\n",
      "|try                     |1    |\n",
      "|usage                   |1    |\n",
      "|prefer                  |1    |\n",
      "|java                    |1    |\n",
      "|web                     |1    |\n",
      "|available               |1    |\n",
      "|3a                      |1    |\n",
      "|dataframes              |1    |\n",
      "|about                   |1    |\n",
      "|unified                 |1    |\n",
      "|r                       |1    |\n",
      "|large                   |1    |\n",
      "|first                   |1    |\n",
      "|2fspan                  |1    |\n",
      "|testing                 |1    |\n",
      "|different               |1    |\n",
      "|xml                     |1    |\n",
      "|changed                 |1    |\n",
      "|dynamic                 |1    |\n",
      "|only                    |1    |\n",
      "|start                   |1    |\n",
      "|have                    |1    |\n",
      "|analysis                |1    |\n",
      "|its                     |1    |\n",
      "|runs                    |1    |\n",
      "|computation             |1    |\n",
      "|note                    |1    |\n",
      "|threads                 |1    |\n",
      "|uses                    |1    |\n",
      "|thriftserver            |1    |\n",
      "|find                    |1    |\n",
      "|2fpyspark               |1    |\n",
      "|from                    |1    |\n",
      "|analytics               |1    |\n",
      "|tips                    |1    |\n",
      "|need                    |1    |\n",
      "|2fbody                  |1    |\n",
      "|through                 |1    |\n",
      "|against                 |1    |\n",
      "|no                      |1    |\n",
      "|help                    |1    |\n",
      "|development             |1    |\n",
      "|get                     |1    |\n",
      "|brightgreen             |1    |\n",
      "|md                      |1    |\n",
      "|many                    |1    |\n",
      "|supported               |1    |\n",
      "|directory               |1    |\n",
      "|pre                     |1    |\n",
      "|distribution            |1    |\n",
      "+------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "def wordCount(wordListDF):\n",
    "    return (wordListDF.groupBy('word').count())\n",
    "WordsAndCountsDF = wordCount(WordsDF)\n",
    "topWordsAndCountsDF = WordsAndCountsDF.orderBy(\"count\", ascending=0)\n",
    "topWordsAndCountsDF.show(689, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "topWordsAndCountsDF.toPandas().to_csv('word-count.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
